# ===========================================
# LLM Provider Configuration
# ===========================================

# Choose your LLM provider: 'anthropic', 'openai', or 'ollama'
# Default: 'anthropic'
LLM_PROVIDER=anthropic

# ===========================================
# Anthropic (Claude) Configuration
# ===========================================
# Get your API key from: https://console.anthropic.com/settings/keys
# Recommended model: claude-3-5-sonnet-20241022 (best), claude-3-haiku-20240307 (fast & cheap)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ===========================================
# OpenAI Configuration
# ===========================================
# Get your API key from: https://platform.openai.com/api-keys
# Recommended model: gpt-4o, gpt-4o-mini, gpt-4-turbo
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# ===========================================
# Ollama Configuration (Local LLM)
# ===========================================
# Ollama base URL (default: http://localhost:11434)
# Install Ollama from: https://ollama.ai
# Popular models: llama3.2, mistral, phi3, codellama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ===========================================
# Optional: GitHub Token
# ===========================================
# For GitHub integration features (optional)
# Generate a token at: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here
